<!DOCTYPE HTML>
<html>
<head>
	<meta charset="utf-8">
	<title>  
	  
  	klauscc
  	
	</title>

  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">

	<link href="atom.xml" rel="alternate" title="klauscc" type="application/atom+xml">

	<link href="asset/stylesheets/screen.css" media="screen, projection" rel="stylesheet" type="text/css">
	<link href="asset/stylesheets/font-awesome.min.css" media="screen, projection" rel="stylesheet" type="text/css">
	<script src="asset/javascripts/jquery.min.js"></script>
	<script src="asset/highlightjs/highlight.pack.js"></script>
	<link href="asset/highlightjs/styles/solarized_dark.css" media="screen, projection" rel="stylesheet" type="text/css">
<script>hljs.initHighlightingOnLoad();</script>

	<!--[if lt IE 9]><script src="asset/javascripts/html5.js"></script><![endif]-->
	<!-- <link href='http://fonts.googleapis.com/css?family=Nunito:400,300,700' rel='stylesheet' type='text/css'> -->
	<style type="text/css">
/* latin */
@font-face {
  font-family: 'Nunito';
  font-style: normal;
  font-weight: 300;
  src: local('Nunito-Light'), url(asset/font/1TiHc9yag0wq3lDO9cw0voX0hVgzZQUfRDuZrPvH3D8.woff2) format('woff2');
  unicode-range: U+0000-00FF, U+0131, U+0152-0153, U+02C6, U+02DA, U+02DC, U+2000-206F, U+2074, U+20AC, U+2212, U+2215, U+E0FF, U+EFFD, U+F000;
}
/* latin */
@font-face {
  font-family: 'Nunito';
  font-style: normal;
  font-weight: 400;
  src: local('Nunito-Regular'), url(asset/font/6TbRXKWJjpj6V2v_WyRbMX-_kf6ByYO6CLYdB4HQE-Y.woff2) format('woff2');
  unicode-range: U+0000-00FF, U+0131, U+0152-0153, U+02C6, U+02DA, U+02DC, U+2000-206F, U+2074, U+20AC, U+2212, U+2215, U+E0FF, U+EFFD, U+F000;
}
/* latin */
@font-face {
  font-family: 'Nunito';
  font-style: normal;
  font-weight: 700;
  src: local('Nunito-Bold'), url(asset/font/TttUCfJ272GBgSKaOaD7KoX0hVgzZQUfRDuZrPvH3D8.woff2) format('woff2');
  unicode-range: U+0000-00FF, U+0131, U+0152-0153, U+02C6, U+02DA, U+02DC, U+2000-206F, U+2074, U+20AC, U+2212, U+2215, U+E0FF, U+EFFD, U+F000;
}
	</style>
	
	<style type="text/css">
	.container .left-col{ opacity: 1;}
	#pagenavi a{ font-size: 1.3em;}
	#pagenavi .next:before{ top: 3px;}
	#pagenavi .prev:before{ top: 3px;}
	.container .mid-col .mid-col-container #content .archives .title{ font-size: 1.5em;}
	.container .mid-col .mid-col-container #content article{ padding: 15px 0px;}
	#header .subtitle {
		line-height: 1.2em;
		padding-top: 8px;
	}
	article pre{ background: none; border: none; padding: 0;}
	article .entry-content{text-align: left;}
	.share-comment{ padding: 25px 0px; clear: both;}
	hr{ margin: 20px 0px;border: 0; border-top:solid 1px #ddd;}
	</style>
  

</head>


<body>
	<div class="container">
		<div class="left-col">
			<div class="intrude-less">
				<header id="header" class="inner">
				 
					
					<h1><a href="index.html">klauscc</a></h1>
					<p class="subtitle">Klaus 的博客</p>
					<nav id="main-nav">
						<ul class="main">
						
						  <li id=""><a target="self" href="index.html">Home</a></li>
						
						  <li id=""><a target="_self" href="archives.html">Archives</a></li>
						
						</ul>
					</nav>

					<nav id="sub-nav">
						<div class="social">










<a target="_blank" class="github" target="_blank" href="https://github.com/klauscc" title="GitHub">GitHub</a>
<a target="_blank" class="email" href="mailto:klaus.cheng@qq.com" title="Email">Email</a>

								

								<a class="rss" href="atom.xml" title="RSS">RSS</a>
							
						</div>
					</nav>
				</header>				
			</div>
		</div>	
		<div class="mid-col">
			<div class="mid-col-container"> <div id="content" class="inner">
<div itemscope itemtype="http://schema.org/Blog">


	<article class="post" itemprop="blogPost" itemscope itemtype="http://schema.org/BlogPosting">
		<div class="meta">
			<div class="date">
				<time datetime="2017-05-16T18:06:16+08:00" itemprop="datePublished">2017/5/16</time>
			</div>
			<div class="tags">posted in 
			
			    <a class='category' href='theory.html'>theory</a>&nbsp;
			 
			</div>
		</div>
		<h1 class="title" itemprop="name"><a href="Recurrent%20Neural%20Networks%E5%89%8D%E9%A6%88%E5%8F%8D%E9%A6%88%E6%8E%A8%E5%AF%BC.html" itemprop="url">
		Recurrent Neural Networks前馈反馈推导</a></h1>
		<div class="entry-content" itemprop="articleBody">
			
			<ul>
<li>
<a href="#toc_0">1. Introduction</a>
</li>
<li>
<a href="#toc_1">2. Forward Pass</a>
</li>
<li>
<a href="#toc_2">3. Backward Pass</a>
</li>
</ul>


<h2 id="toc_0">1. Introduction</h2>

<p><img src="media/14949291764036/14949296062380.jpg" alt=""/></p>

<p><img src="media/14949291764036/14949295667284.jpg" alt=""/></p>

<p>输入一个时间序列X(I,T),输出一个时间序列Y(K,T), 时间t+1时刻的神经元会利用到t时刻的输出值。</p>

<h2 id="toc_1">2. Forward Pass</h2>

<p>前馈从输入层到输出层<br/>
考虑一个RNN:<br/>
    1. 输入层为I个神经元，序列长度为T。则输入x维度为(I,T),维度不考虑batch_size<br/>
    2. 隐层(hidden layer)有H个神经元<br/>
    3. 输出层有K个神经元.输出维度为(K,T)</p>

<p>输入为\(x:\{x^1,x^2,...,x^T\}\),其中\(x^t = \{x_1^t,x_2^t,...,x_I^T\}\)。则\(x_i^t\)为时间t第i个神经元的输入。<br/>
对于第L层，\(a_i^t\)为这一层的输入，\(b_i^t\)为这一层的输出。这一层的权重\(W = \{w_{ij}\}_{h\times k}\),h为L-1层的神经元个数，k为L层的神经元个数。\(w_{ij}\)为第L-1层第i个神经元与第L层第j个神经元的连接权重。</p>

<p>每一层的输入输出如下。\(\theta(x)为激活函数，rnn中一般为sigmoid。\theta&#39;(x) = \theta(x)(1-\theta(1-x))\)<br/>
Hidden Layer:<br/>
    1. Input(x): \(x: \{x_i^t\}\)<br/>
    2. Output(\(b_h^t\)):<br/>
    <center>\(a_h^t = \sum_{i=1}^{I}w_{ih}x_i^t + \sum_{h&#39;=1}^{H}w_{h&#39;h}b_{h&#39;}^{t-1}\)<br/>
    \(b_h^t = \theta(a_h^t)\)</center><br/>
Output Layer:<br/>
    1. Input(\(b_h^t\))<br/>
    2. Output:<br/>
<center><br/>
    \(a_k^t = \sum_{h=1}^Hw_{hk}b_h^t\)<br/>
    \(b_k^t = \theta(a_k^t)\)</center></p>

<p>写成矩阵形式为<br/>
    \(A_H^t = W_1^TX^t+ W_2^TA_H^{t-1}\), shape: (H,1)<br/><br/>
    \(B_H^t = \theta(A_H^t)\), shape:(H,1)， \(\theta(V)\)表示对矩阵\(V\)的每个元素\(v_{ij}\)用\(\theta(v_{ij})\)进行计算<br/>
    \(A_K^t = W_3^TB_H^t\), shape: (K,1)<br/>
    \(B_K^t = \theta(A_K^t)\), shape:(K,1)</p>

<p>注意到求\(A_H^t\)需要依赖于\(A_H^{t-1}\)，所以隐层在时间维度T是无法用矩阵并行运算而需要从t=0到t=T-1依次计算。但是反向求梯度的时候可以将时间维度T并行起来。</p>

<h2 id="toc_2">3. Backward Pass</h2>

<p>反向传播从输出层反向传梯度到输入层</p>

<p><strong>输出层</strong>: with respect to Layer Output(\(b_k^t\)), Parameter(\(w_{hk}\)), Input(\(b_h^t \))<br/>
\(\delta(b_k^t) = \frac{\partial L}{\partial b_k^t}\)<br/>
\(\delta(a_k^t) = \theta&#39;(a_k^t)\delta(b_k^t)\)<br/>
\(\delta(w_{hk}) = \frac{\partial L}{\partial w_{hk}} = \sum_{t=1}^{T}\frac{\partial L}{\partial a_k^t}* \frac{\partial a_k^t}{w_{hk}} = \sum_{t=1}^{T} \delta(a_k^t)b_h^t \)<br/>
<strong>隐层</strong>: with respect to Layer Output(\(b_h^t\)),parameter(\(w_{ih}, w_(h&#39;h)\)), input(\(x_i^t\))<br/>
\(\delta(b_h^t) = \frac{\partial L}{\partial b_h^t} = \sum_{k=1}^{K}\frac{\partial L}{\partial a_k^t}*\frac{\partial a_k^t}{b_h^t} + \sum_{h&#39;=1}^{H}\frac{\partial L}{\partial a_{h&#39;}^{t+1 }}*\frac{\partial a_{h&#39;}^{t+1}}{\partial b_h^{t}} \)<br/>
 \( = \sum_{k=1}^{K}\delta(a_k^t)w_{hk} + \sum_{h&#39;=1}^{H}\delta(b_{h&#39;}^{t+1})w_{hh&#39;}\)<br/>
 \(\delta(a_h^t) = \frac{\partial L}{a_h^t} = \frac{\partial L}{b_h^t} * \frac{\partial b_h^t}{a_h^t} = \delta(b_h^t) \theta&#39;(a_h^t)\)</p>

<p>\(\delta(w_{ih}) = \frac{\partial L}{\partial w_{ih}} = \frac{\partial L}{\partial a_h^t} * \frac{\partial a_h^t}{\partial w_{ih}} = \delta(a_h^t) * x_i^t\)</p>

<p>\(\delta(w_{h&#39;h}) = \frac{\partial L}{\partial w_{h&#39;h}} = \frac{\partial L}{\partial a_h^t}* \frac{\partial a_h^t}{\partial w_{h&#39;h}} = \sum_{t=1}^{T}\delta(a_h^t)b_{h&#39;}^{t-1}\)</p>

<p>写成矩阵的形式:<br/>
计Loss函数关于某个变量V(input, output, parameter)的梯度\(Grad(V) = \Delta(V)\)</p>

<p>输出层:输入\(B_H:(H,T)\) 输出\(B_K:(K,T)\) 参数\(W_3:(H,K)\) <br/>
\(\Delta(B_K) = \frac{\partial L}{\partial B_K} \) shape(K,T)<br/>
\(\Delta(A_K) = \Delta(B_K) \odot \theta&#39;(A_K)\) shape(K,T)， \(\odot\)表示element-wise 乘法，即两个size相同的矩阵的每个对应元素相互乘起来。<br/>
\(\Delta(W_3) = B_H*\Delta^T(A_K)\) shape(H,K)<br/>
隐层: 输入\(X:(I,T)\) 输出\(B_H:(H,T)\) 参数\(W_1:(I,H),W_2:(H,H) \)<br/>
\(\Delta(B_H) = W_3*\Delta(A_K) + W_2*(\Delta(B_H) &lt;&lt; 1, axis=2)\) shape(H,T). \(\Delta(B_H) &lt;&lt; 1, axis=2\) 表示矩阵\(\Delta(B_H)\)在时间T的维度向左移位1次<br/>
\(\Delta(A_H) = \Delta(B_H) \odot \theta&#39;(B_H)\) ,shape(H,T)<br/>
\(\Delta(W_1) = X * \Delta(A_H) \)<br/>
\(\Delta(W_2) = (B_H &gt;&gt; 1, axis=2)*\Delta^T(A_H)\), shape(H,H)</p>

<p>对于第L层，求出其输出梯度，从而求出其输入梯度。利用输出输入梯度，可以求得第L层参数梯度，从而更新第L层参数。<br/>
而第L-1层的输出梯度为第L层的输入梯度。<br/>
依次反向传播更新每层参数。</p>


			
			
		</div>

	</article>
 
	<article class="post" itemprop="blogPost" itemscope itemtype="http://schema.org/BlogPosting">
		<div class="meta">
			<div class="date">
				<time datetime="2017-02-13T14:28:05+08:00" itemprop="datePublished">2017/2/13</time>
			</div>
			<div class="tags">posted in 
			
			    <a class='category' href='linux.html'>linux</a>&nbsp;
			 
			</div>
		</div>
		<h1 class="title" itemprop="name"><a href="shadowsocks-proxychains-genpac-on-centos.html" itemprop="url">
		centos 安装shadowsocks,proxychains,genpac科学上网</a></h1>
		<div class="entry-content" itemprop="articleBody">
			
			<p>本文说明的是如何让centos系统能够翻墙，而不是作为ss服务器。<br/>
shadowsocks 翻墙客户端<br/>
proxychains 让命令行可以通过ss代理<br/>
genpac生成proxy.pac文件以达到局部代理效果</p>



			 
			<a href="shadowsocks-proxychains-genpac-on-centos.html#more" class="more-link">Read on &rarr;</a>
    		
			
		</div>

	</article>
 
	<article class="post" itemprop="blogPost" itemscope itemtype="http://schema.org/BlogPosting">
		<div class="meta">
			<div class="date">
				<time datetime="2017-01-15T14:46:58+08:00" itemprop="datePublished">2017/1/15</time>
			</div>
			<div class="tags">posted in 
			
			    <a class='category' href='deep%20learning.html'>deep learning</a>&nbsp;
			 
			</div>
		</div>
		<h1 class="title" itemprop="name"><a href="caffe-simple-beginner-guide.html" itemprop="url">
		深度学习、caffe简要入门指南</a></h1>
		<div class="entry-content" itemprop="articleBody">
			
			<p>近年来，深度学习是机器学习的一大潮流。它在计算机视觉CV，自然语言处理NLP等领域取得了极大的成就。本文以深度学习框架Caffe作为工具简要讲解深度学习入门。</p>

<p><strong>对深度学习和CNN比较了解的可以直接跳至第四节，对caffe比较了解的可以直接跳过本教程。</strong></p>



			 
			<a href="caffe-simple-beginner-guide.html#more" class="more-link">Read on &rarr;</a>
    		
			
		</div>

	</article>
 
	<article class="post" itemprop="blogPost" itemscope itemtype="http://schema.org/BlogPosting">
		<div class="meta">
			<div class="date">
				<time datetime="2016-12-07T12:57:59+08:00" itemprop="datePublished">2016/12/7</time>
			</div>
			<div class="tags">posted in 
			
			    <a class='category' href='linux.html'>linux</a>&nbsp;
			
			    <a class='category' href='deep%20learning.html'>deep learning</a>&nbsp;
			 
			</div>
		</div>
		<h1 class="title" itemprop="name"><a href="centos-setup-deeplearning-environment.html" itemprop="url">
		centos7.0安装配置，cuda,cudnn安装，anaconda安装，深度学习框架caffe,torch,theano,tensorflow安装</a></h1>
		<div class="entry-content" itemprop="articleBody">
			
			<p>深度学习在linux上面会比windows上面方便很多，在windows上那叫个折腾。本文将会介绍centos7.0 的<br/>
安装，cuda和cudnn的安装，anaconda安装，以及各种深度学习框架的安装。</p>

<p>深度学习是计算密集型任务，不推荐在虚拟机中运行，装cuda和cudnn需要有nvidia显卡。</p>



			 
			<a href="centos-setup-deeplearning-environment.html#more" class="more-link">Read on &rarr;</a>
    		
			
		</div>

	</article>
 
	<article class="post" itemprop="blogPost" itemscope itemtype="http://schema.org/BlogPosting">
		<div class="meta">
			<div class="date">
				<time datetime="2016-07-31T21:40:01+08:00" itemprop="datePublished">2016/7/31</time>
			</div>
			<div class="tags">posted in 
			
			    <a class='category' href='Digital%20Image%20Forensics.html'>Digital Image Forensics</a>&nbsp;
			 
			</div>
		</div>
		<h1 class="title" itemprop="name"><a href="14699724013434.html" itemprop="url">
		Double Jpeg detection with the same quantization matrix (Notes)</a></h1>
		<div class="entry-content" itemprop="articleBody">
			
			<h2 id="toc_0">1. Introduction</h2>

<p>介绍一下几篇论文中等质量双压缩检测的方法，备忘。State of the-art double jepg compression detection with the same quantization matrix. </p>

<h2 id="toc_1">2. Methods</h2>

<h3 id="toc_2">2.1 Proposed by Fangjun et al.</h3>

<p><a href="http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5560817">Detecting Double JPEG Compression With the Same Quantization Matrix</a> </p>

<h4 id="toc_3">2.1.1 jpeg压缩和解压缩过程导致的三种误差</h4>

<p>i. 量化误差 压缩过程中，DCT系数量化导致的误差<br/>
ii. 截断误差 解压缩过程中，IDCT变换可能导致值在[0,255]之外，需要截断到0或者255<br/>
iii. 舍入误差  解压缩， IDCT变换得到的值为浮点数，需要舍入为最接近的整数</p>

<h4 id="toc_4">2.1.2 jpeg多重压缩统计特征</h4>

<p>\(J_n\)代表压缩n次的Jpeg图片，\(D_n\)代表 \(J_n\)和\(J_{n+1}\)中JPEG系数（量化后的DCT系数）不一样的个数，\(S_n\)代表\(J_n\)中非0 JPEG系数的个数。<br/>
<strong>统计特征：</strong>随着n增加，\(D_n\)单调减小</p>



			 
			<a href="14699724013434.html#more" class="more-link">Read on &rarr;</a>
    		
			
		</div>

	</article>
 
	<article class="post" itemprop="blogPost" itemscope itemtype="http://schema.org/BlogPosting">
		<div class="meta">
			<div class="date">
				<time datetime="2016-07-31T21:34:09+08:00" itemprop="datePublished">2016/7/31</time>
			</div>
			<div class="tags">posted in 
			
			    <a class='category' href='Digital%20Image%20Forensics.html'>Digital Image Forensics</a>&nbsp;
			 
			</div>
		</div>
		<h1 class="title" itemprop="name"><a href="14699720497183.html" itemprop="url">
		Digital image forensics: a booklet for beginners</a></h1>
		<div class="entry-content" itemprop="articleBody">
			
			<h3 id="toc_0">1. Introduction</h3>

<ul>
<li><strong>Digital image forensics(DIF)</strong>

<ul>
<li>two principal research paths:

<ol>
<li>attempt at answering question a)(device captured the image as declared), by <strong>performing some kind of ballistic analysis</strong> to identify the device that captured the image, or at least to determine which devices did not capture it. </li>
<li><strong>exposing traces of semantic manipulation</strong> (i.e. forgeries) by studying inconsistencies in natural image statistics. </li>
</ol></li>
</ul></li>
</ul>

<h3 id="toc_1">2. the role of digital image forensics in multimedia security</h3>

<ul>
<li><p>acquisition process and the tampering techniques leave subtle traces</p>

<ul>
<li><strong>active protection</strong>: watermarking</li>
</ul>

<h2 id="toc_2">- <strong>passive protection</strong>: tools in digital image forensics</h2>



			 
			<a href="14699720497183.html#more" class="more-link">Read on &rarr;</a>
    		
			
		</div>

	</article>
  

</div>
<nav id="pagenavi">
	 
	
	<div class="center"><a href="archives.html">Blog Archives</a></div>

</nav>

</div>



        </div>
			<footer id="footer" class="inner">Copyright &copy; 2014
Powered by <a target="_blank" href="http://www.mweb.im">MWeb</a> &nbsp;&nbsp; 
Theme by <a href="http://shashankmehta.in/archive/2012/greyshade.html">Shashank Mehta</a>
      </footer>
		</div>
	</div>

  
    
<script src="asset/chart/all-min.js"></script><script type="text/javascript">$(function(){    var mwebii=0;    var mwebChartEleId = 'mweb-chart-ele-';    $('pre>code').each(function(){        mwebii++;        var eleiid = mwebChartEleId+mwebii;        if($(this).hasClass('language-sequence')){            var ele = $(this).addClass('nohighlight').parent();            $('<div id="'+eleiid+'"></div>').insertAfter(ele);            ele.hide();            var diagram = Diagram.parse($(this).text());            diagram.drawSVG(eleiid,{theme: 'simple'});        }else if($(this).hasClass('language-flow')){            var ele = $(this).addClass('nohighlight').parent();            $('<div id="'+eleiid+'"></div>').insertAfter(ele);            ele.hide();            var diagram = flowchart.parse($(this).text());            diagram.drawSVG(eleiid);        }    });});</script>
<script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><script type="text/x-mathjax-config">MathJax.Hub.Config({TeX: { equationNumbers: { autoNumber: "AMS" } }});</script>

</body>
</html>